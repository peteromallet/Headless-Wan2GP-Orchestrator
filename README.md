# Runpod GPU Worker Orchestrator

A lightweight service that automatically spawns, monitors, and tears down Runpod GPU workers based on task demand tracked in Supabase.

## Quick Start

1. Follow the setup checklist in `user_checklist.md`
2. Copy `env.example` to `.env` and fill in your API keys
3. Install dependencies: `pip install -r requirements.txt`
4. Set up database schema: `python scripts/setup_database.py`
5. Run orchestrator: `python -m gpu_orchestrator.main single`

## Deployment

See `DEPLOYMENT_GUIDE.md` for comprehensive deployment options. **Recommended**: Simple cloud VM with cron scheduling.

- ğŸ¥‡ **Most users**: VM + Cron (reliable, simple, ~$5-15/month)
- ğŸ³ **Containers**: Docker Compose, AWS ECS, Kubernetes, Google Cloud Run
- âŒ **Avoid**: Supabase Edge Functions (timeout and reliability issues)

## Project Structure

```
orchestrator/           # Main orchestrator logic
â”œâ”€â”€ __init__.py
â”œâ”€â”€ main.py            # Entry point
â”œâ”€â”€ database.py        # Supabase helpers
â”œâ”€â”€ runpod_client.py   # Runpod API wrapper
â””â”€â”€ control_loop.py    # Core orchestration logic

# GPU workers run Headless-Wan2GP (separate repo)
# See: https://github.com/peteromallet/Headless-Wan2GP

scripts/               # CLI utilities
â”œâ”€â”€ setup_database.py  # Database schema setup
â”œâ”€â”€ test_supabase.py   # Connection tests
â”œâ”€â”€ test_runpod.py     # Runpod API tests
â””â”€â”€ spawn_gpu.py       # Manual GPU spawning

tests/                 # Test suite
â””â”€â”€ test_*.py
```

## Documentation

- `orchestrator_plan.md` - Detailed implementation plan and architecture
- `user_checklist.md` - Setup prerequisites and testing steps

## Development

Run tests: `pytest`
Format code: `black . && isort .`
Type check: `mypy orchestrator/` 